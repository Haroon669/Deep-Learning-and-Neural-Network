{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Learning :"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Deep Learning is mostly used to Solve any Classification or Regression Problem.\n",
    "It is being used for Unstructure Data like Image,Video,Text,Audio etc.\n",
    "\n",
    "Deep Learning uses Neural Networks to build deep Models which understand Complex Relation among the variables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Network :"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Neural Network get its name from Neuron in Human Brain and work like Same as Brain Neuron.It work best when data is Non-Linear.\n",
    "\n",
    "Neural Netwok has Input Nodes, Hidden Layers of Nodes, Output Nodes.\n",
    "Each Input Node carry weight according to Importance in the Model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Forward Propagation :"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To Predict Output Neural Network we use Forward Propagation.Forward Propagation uses Multiplication of input Nodes by weight\n",
    "to calculate the next connecting Nodes.It works in a dot Product Method.It only move in Forward Direction.It depend on Activation Function to decide output."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Activation Function :"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Activation Function decides whether information the Node has is important for the Network or Not.If activation function activate the Node.then the value of Node is used to find the next layer of Node.If not the output is no longer used as input of Next Layer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Types of Activation Function :"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Binary Step Function:\n",
    "If Node cross Threshold value then Node is activated otherwise it is Not Activated."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Function:\n",
    "If uses linear function eg f(x) = g(x) for Activation.The input x will  be converted to gx for the Next Node."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sigmoid  Function:\n",
    "If is non linear function eg 1/(1+e^-x). It ranges from 0 and 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tanh Function:\n",
    "If is same like Sigmoid function eg 1/(1+e^(-2x))-1. It ranges from -1 and 1.It also include Negative Values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Relu Function:\n",
    "It stand for Rectified Linear Unit.eg f(x) = Max(0,x).t does not activate all the neurons all at once.make backPropagation\n",
    "efficient.It does not Activate Negative Nodes so Only few Nodes will be Activated.Relu work best with Hidden Layer of Nodes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SoftMax Function:\n",
    "Mostly used for Classification Problem.It gives Probability of input belonging to Particular Output class.It differentiate \n",
    "betwen classes for Output Response Variable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bias :\n",
    "Bias help us to shift te output up and down in order to learn algorithm best."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BackPropagation :\n",
    " Back Propagation is used to train the Network.It is used to minimize cost function by optimize weight and bias.BackPropagation is done by the network run through Multiple Time called as Epoch.It run until error determine by the cose remain very small. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BackPropagation Techniques :"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mini Batch Gradient Descent.\n",
    "A small batch of Training sample eg 100 are feeded into Network sequentially and weights are updated accordingly.Final Average weight is calculated after all Batches done executing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stochastic Gradient Descent.Â¶\n",
    "it is used for real time output by using one record at a time to compute weight."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Full Batch Gradient Descent.\n",
    "It uses all Training Sample for each Epoch or turn. weights are updated based on output from Complete Batch."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cost Error Function:\n",
    "While using backpropagation.Different Cost function is used to reduce Error.Thes Functions are\n",
    "\n",
    "1) Mean Squared Error Function      2)      Cross Entropy Function       3) Negative Log-Likelihood loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Learning Rate :\n",
    "It control change in weight from one iteration to another"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
